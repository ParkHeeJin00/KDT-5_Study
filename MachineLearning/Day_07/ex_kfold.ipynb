{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 교차 검증\n",
    "- 부족한 데이터셋 및 특정 데이터에 과대적한되는 문제 해결하기 위한 방안\n",
    "- 학습 데이터셋을 일정 크기의 데이터로 n개 분리 후 1/n은 검증용, 나머지는 학습용으로 사용"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35746294a64062eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "[1] 모듈 로딩 <hr>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8186ee2ba8754851"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([[1, 2],[3,4],[1, 2],[3,4]])\n",
    "y = np.array([1,2,3,4])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.501560500Z",
     "start_time": "2024-03-05T06:43:02.471216Z"
    }
   },
   "id": "7e7f5f2bff26f84f",
   "execution_count": 193
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# KFold 인스턴스 생성 => 데이터를 2개로 분할해주는 객체\n",
    "k_fold = KFold(n_splits=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.502558400Z",
     "start_time": "2024-03-05T06:43:02.486958600Z"
    }
   },
   "id": "65b4ccddf474afc4",
   "execution_count": 194
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "datasets = k_fold.split(x) # 반환값 : ndarray"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.524472100Z",
     "start_time": "2024-03-05T06:43:02.505716600Z"
    }
   },
   "id": "3b94ab2969eaf81d",
   "execution_count": 195
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n"
     ]
    }
   ],
   "source": [
    "for train,test in datasets:\n",
    "    print(train,test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.528650100Z",
     "start_time": "2024-03-05T06:43:02.515139500Z"
    }
   },
   "id": "222e8b9dd8c009bd",
   "execution_count": 196
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56 entries, 0 to 55\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Weight  56 non-null     float64\n",
      " 1   Length  56 non-null     float64\n",
      " 2   Height  56 non-null     float64\n",
      " 3   Width   56 non-null     float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 1.9 KB\n"
     ]
    }
   ],
   "source": [
    "### perch.csv 파일 데이터 기본 5등분\n",
    "perchDF = pd.read_csv('../data/perch3.csv')\n",
    "perchDF.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.552874Z",
     "start_time": "2024-03-05T06:43:02.531708200Z"
    }
   },
   "id": "2362fd85276e7e09",
   "execution_count": 197
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# perchDF => 5등분\n",
    "fold_5 = KFold(n_splits=5)\n",
    "#n_splits = k \n",
    "# train = k-1/k\n",
    "# test = 1/k\n",
    "\n",
    "datasets = fold_5.split(perchDF) # 비율을 맞춰야 함 => fold.split(x,y) -> y 추가"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.596084300Z",
     "start_time": "2024-03-05T06:43:02.546557400Z"
    }
   },
   "id": "ded9bc35b65adf8c",
   "execution_count": 198
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 => ((44,), (12,))\n",
      "[12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35\n",
      " 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "2 => ((45,), (11,))\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 23 24 25 26 27 28 29 30 31 32 33 34\n",
      " 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55]\n",
      "[12 13 14 15 16 17 18 19 20 21 22]\n",
      "3 => ((45,), (11,))\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 34\n",
      " 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55]\n",
      "[23 24 25 26 27 28 29 30 31 32 33]\n",
      "4 => ((45,), (11,))\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 45 46 47 48 49 50 51 52 53 54 55]\n",
      "[34 35 36 37 38 39 40 41 42 43 44]\n",
      "5 => ((45,), (11,))\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44]\n",
      "[45 46 47 48 49 50 51 52 53 54 55]\n"
     ]
    }
   ],
   "source": [
    "for idx,(train,test) in enumerate(datasets):   # 튜플로 반환되는 값은 받을때도 튜플에다 지정해줘야 언패킹 가능\n",
    "    print(f'{idx+1} => {train.shape, test.shape}')  # 총 5등분으로 나누어진 것 확인 가능\n",
    "    print(train, test, sep ='\\n') # 행 번호"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.597136900Z",
     "start_time": "2024-03-05T06:43:02.564485700Z"
    }
   },
   "id": "1871075e8f7cf821",
   "execution_count": 199
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal.length  150 non-null    float64\n",
      " 1   sepal.width   150 non-null    float64\n",
      " 2   petal.length  150 non-null    float64\n",
      " 3   petal.width   150 non-null    float64\n",
      " 4   variety       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "irisDF = pd.read_csv('../data/iris.csv')\n",
    "irisDF.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.618029700Z",
     "start_time": "2024-03-05T06:43:02.580375100Z"
    }
   },
   "id": "22ad54a159bc5f24",
   "execution_count": 200
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "featureDF = irisDF[irisDF.columns[:-1]]\n",
    "targetSR = irisDF['variety']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.619108500Z",
     "start_time": "2024-03-05T06:43:02.595086200Z"
    }
   },
   "id": "741cf6a01592aa29",
   "execution_count": 201
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=3,shuffle = True )\n",
    "ret_k = k_fold.split(featureDF,targetSR) # generator는 한번 순회하면 못쓰는 타입"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:43:02.629592Z",
     "start_time": "2024-03-05T06:43:02.611714400Z"
    }
   },
   "id": "8914fc3852386adf",
   "execution_count": 202
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================1=================\n",
      "variety\n",
      "Virginica     35\n",
      "Versicolor    33\n",
      "Setosa        32\n",
      "Name: count, dtype: int64\n",
      "================2=================\n",
      "variety\n",
      "Setosa        34\n",
      "Virginica     34\n",
      "Versicolor    32\n",
      "Name: count, dtype: int64\n",
      "================3=================\n",
      "variety\n",
      "Versicolor    35\n",
      "Setosa        34\n",
      "Virginica     31\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ret_k = k_fold.split(featureDF)\n",
    "for idx,(train,test) in enumerate(ret_k):\n",
    "    print(f'================{idx+1}=================') \n",
    "    print(targetSR[train].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:48:23.208149900Z",
     "start_time": "2024-03-05T06:48:23.194483300Z"
    }
   },
   "id": "678f5f92c00f1235",
   "execution_count": 217
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variety\n",
      "Virginica     0.35\n",
      "Setosa        0.33\n",
      "Versicolor    0.32\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Versicolor    0.36\n",
      "Setosa        0.34\n",
      "Virginica     0.30\n",
      "Name: count, dtype: float64\n",
      "0.95\n",
      "variety\n",
      "Virginica     0.37\n",
      "Versicolor    0.32\n",
      "Setosa        0.31\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Setosa        0.38\n",
      "Versicolor    0.36\n",
      "Virginica     0.26\n",
      "Name: count, dtype: float64\n",
      "0.96\n",
      "variety\n",
      "Setosa        0.36\n",
      "Versicolor    0.36\n",
      "Virginica     0.28\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Virginica     0.44\n",
      "Setosa        0.28\n",
      "Versicolor    0.28\n",
      "Name: count, dtype: float64\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "ret_k = k_fold.split(featureDF,targetSR)\n",
    "trainList = []\n",
    "testList = []\n",
    "for idx,(train,test) in enumerate(ret_k):\n",
    "    # train = train.tolist()  # 학습용 데이터 인덱스\n",
    "    # test = test.tolist()  # 테스트용 데이터 인덱스\n",
    "    \n",
    "    # 비율 확인\n",
    "    print(targetSR[train].value_counts()/len(train))\n",
    "    print(targetSR[test].value_counts()/len(test))\n",
    "    \n",
    "    xtrain = featureDF.loc[train,:]\n",
    "    ytrain = targetSR[train]  # 수정\n",
    "    \n",
    "    xtest = featureDF.loc[test,:]  # 수정\n",
    "    ytest = targetSR[test]\n",
    "    \n",
    "    # 분류 모델 학습\n",
    "    \n",
    "    model = LogisticRegression(max_iter=3000, solver = 'liblinear') # 파라미터 for문 돌려서 튜닝\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    # 훈련 및 검증용 성능\n",
    "    train_score = model.score(xtrain, ytrain)\n",
    "    test_score = model.score(xtest, ytest)\n",
    "    print(train_score)\n",
    "    \n",
    "    # 예측\n",
    "    pre = model.predict(xtest)\n",
    "    \n",
    "    trainList.append(train_score)\n",
    "    testList.append(test_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:46:57.749492500Z",
     "start_time": "2024-03-05T06:46:57.718268300Z"
    }
   },
   "id": "ff3f829b3b743e9a",
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "0.9533333333333333"
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(trainList)/len(trainList)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T06:47:01.174718100Z",
     "start_time": "2024-03-05T06:47:01.160Z"
    }
   },
   "id": "d10a2c5cb9dde02",
   "execution_count": 216
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variety\n",
      "Setosa        0.38\n",
      "Virginica     0.34\n",
      "Versicolor    0.28\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Versicolor    0.44\n",
      "Virginica     0.32\n",
      "Setosa        0.24\n",
      "Name: count, dtype: float64\n",
      "0.97\n",
      "variety\n",
      "Virginica     0.39\n",
      "Versicolor    0.37\n",
      "Setosa        0.24\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Setosa        0.52\n",
      "Versicolor    0.26\n",
      "Virginica     0.22\n",
      "Name: count, dtype: float64\n",
      "0.98\n",
      "variety\n",
      "Setosa        0.38\n",
      "Versicolor    0.35\n",
      "Virginica     0.27\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Virginica     0.46\n",
      "Versicolor    0.30\n",
      "Setosa        0.24\n",
      "Name: count, dtype: float64\n",
      "0.97\n",
      "variety\n",
      "Setosa        0.34\n",
      "Virginica     0.34\n",
      "Versicolor    0.32\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Versicolor    0.36\n",
      "Setosa        0.32\n",
      "Virginica     0.32\n",
      "Name: count, dtype: float64\n",
      "0.97\n",
      "variety\n",
      "Virginica     0.36\n",
      "Versicolor    0.35\n",
      "Setosa        0.29\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Setosa        0.42\n",
      "Versicolor    0.30\n",
      "Virginica     0.28\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdp\\.conda\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kdp\\.conda\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\kdp\\.conda\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99\n",
      "variety\n",
      "Setosa        0.37\n",
      "Versicolor    0.33\n",
      "Virginica     0.30\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Virginica     0.40\n",
      "Versicolor    0.34\n",
      "Setosa        0.26\n",
      "Name: count, dtype: float64\n",
      "0.97\n",
      "variety\n",
      "Virginica     0.40\n",
      "Setosa        0.33\n",
      "Versicolor    0.27\n",
      "Name: count, dtype: float64\n",
      "variety\n",
      "Versicolor    0.46\n",
      "Setosa        0.34\n",
      "Virginica     0.20\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "l1_ratio must be specified when penalty is elasticnet.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[247], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# 분류 모델 학습\u001B[39;00m\n\u001B[0;32m     21\u001B[0m model \u001B[38;5;241m=\u001B[39m LogisticRegression(max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3000\u001B[39m,solver\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msaga\u001B[39m\u001B[38;5;124m'\u001B[39m, penalty\u001B[38;5;241m=\u001B[39mp_name) \u001B[38;5;66;03m# 파라미터 for문 돌려서 튜닝\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mytrain\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# 훈련 및 검증용 성능\u001B[39;00m\n\u001B[0;32m     25\u001B[0m train_score \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mscore(xtrain, ytrain)\n",
      "File \u001B[1;32m~\\.conda\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\EXAM_ML\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1178\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1171\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1172\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1_ratio parameter is only used when penalty is \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1173\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1174\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(penalty=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty)\n\u001B[0;32m   1175\u001B[0m     )\n\u001B[0;32m   1177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124melasticnet\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ml1_ratio \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1178\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ml1_ratio must be specified when penalty is elasticnet.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;66;03m# TODO(1.4): Remove \"none\" option\u001B[39;00m\n\u001B[0;32m   1181\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpenalty \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mValueError\u001B[0m: l1_ratio must be specified when penalty is elasticnet."
     ]
    }
   ],
   "source": [
    "trainList = []\n",
    "testList = []\n",
    "\n",
    "ret_k = k_fold.split(featureDF,targetSR)\n",
    "for idx,(train,test) in enumerate(ret_k):\n",
    "    train = train.tolist()  # 학습용 데이터 인덱스\n",
    "    test = test.tolist()  # 테스트용 데이터 인덱스\n",
    "    \n",
    "    # 비율 확인\n",
    "    print(targetSR[train].value_counts()/len(train))\n",
    "    print(targetSR[test].value_counts()/len(test))\n",
    "    \n",
    "    xtrain = featureDF.loc[train,:]\n",
    "    ytrain = targetSR[train]  # 수정\n",
    "    \n",
    "    xtest = featureDF.loc[test,:]  # 수정\n",
    "    ytest = targetSR[test]\n",
    "    \n",
    "    # 분류 모델 학습\n",
    "    \n",
    "    model = LogisticRegression(max_iter=3000,solver='saga', penalty=p_name) # 파라미터 for문 돌려서 튜닝\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    # 예측\n",
    "    \n",
    "    # 훈련 및 검증용 성능\n",
    "    train_score = model.score(xtrain, ytrain)\n",
    "    test_score = model.score(xtest, ytest)\n",
    "    print(train_score)\n",
    "    trainList.append(train_score)\n",
    "    testList.append(test_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T07:13:54.338991100Z",
     "start_time": "2024-03-05T07:13:54.028328400Z"
    }
   },
   "id": "83a97ce6cde4bc61",
   "execution_count": 247
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
