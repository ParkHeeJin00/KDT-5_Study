{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어 수치화 BOW 방식\n",
    "- 문장 리스트에서 단어들을 추출 후 빈도순으로 번호를 부여 ==> 단어 사전( 단어 집합 )\n",
    "- 생성된 단어 사전을 기준으로 문장을 수치화 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 데이터 준비\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어사전 {'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n"
     ]
    }
   ],
   "source": [
    "# 카운트 기반 단어 벡터화 인스턴스 생성\n",
    "# 문장에 단어들이 나타난 빈도 수에 따라서 정수 인코딩 - countvectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = CountVectorizer(stop_words=['this','is','the','and'])  => 불용어 설정\n",
    "\n",
    "# 단어사전 만들기\n",
    "X = vectorizer.fit(corpus)  # raw_documents = corpus \n",
    "\n",
    "print(f'단어사전 {vectorizer.vocabulary_}') # 단어와 번호(알파벳 순서대로 부여)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third',\n",
       "       'this'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어사전에서 단어만 추출\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# 단어사전 기반으로 문장 ==> 수치화\n",
    "result = vectorizer.transform(corpus)\n",
    "\n",
    "# 단어 사전 출력\n",
    "print(['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third','this'])\n",
    "# 단어 사전의 숫자에 맞춰 문장에 존재하는 단어 횟수를 표시\n",
    "print(result.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['and this', 'document is', 'first document', 'is the', 'is this',\n",
       "       'second document', 'the first', 'the second', 'the third',\n",
       "       'third one', 'this document', 'this is', 'this the'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "X2 = vectorizer2.fit_transform(corpus)\n",
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TF-IDF 방식 수치화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TFIDF 인스턴스 생성\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어사전 단어 : 인덱스 \n",
      "  {'this': 8, 'is': 3, 'the': 6, 'first': 2, 'document': 1, 'second': 5, 'and': 0, 'third': 7, 'one': 4}\n",
      "단어 사전 단어 : IDF \n",
      " [1.91629073 1.22314355 1.51082562 1.         1.91629073 1.91629073\n",
      " 1.         1.91629073 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# 단어 사전 확인\n",
    "print(f'단어사전 단어 : 인덱스 \\n  {vectorizer.vocabulary_}')\n",
    "print(f'단어 사전 단어 : IDF \\n {vectorizer.idf_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524],\n",
       "       [0.        , 0.6876236 , 0.        , 0.28108867, 0.        ,\n",
       "        0.53864762, 0.28108867, 0.        , 0.28108867],\n",
       "       [0.51184851, 0.        , 0.        , 0.26710379, 0.51184851,\n",
       "        0.        , 0.26710379, 0.51184851, 0.26710379],\n",
       "       [0.        , 0.46979139, 0.58028582, 0.38408524, 0.        ,\n",
       "        0.        , 0.38408524, 0.        , 0.38408524]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 벡터 유사도 - 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "doc_list=['if you take the blue pill, the story ends' , \n",
    "          'if you take the red pill, you stay in Wonderland', \n",
    "          'if you take the red pill, I show you how deep the rabbit hole goes']\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "feature_vect = tfidf_vect.fit_transform( doc_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.40207758 0.40425045]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "## cosine_similarity(X, y)\n",
    "# - X : 비교 기준이 되는 문서의 피처 행렬\n",
    "# - y : 비교하고자 하는 문서의 피처 행렬\n",
    "# 0번 문장 가지고 와서 거리 비교하는 코드\n",
    "result = cosine_similarity(feature_vect[0] , feature_vect)\n",
    "print( result )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_NLP38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
