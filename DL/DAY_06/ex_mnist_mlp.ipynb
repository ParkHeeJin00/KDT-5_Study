{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다중 분류 <hr>\n",
    "- 데이터셋 : scikit-learn Fashion MNIST\n",
    "- 데이터수 : 학습용 60000, 테스틍용 10000\n",
    "- 피쳐갯수 : 28 X 28 흑백 이미지로 784\n",
    "- 타겟갯수 : 티셔츠/상의, 바지, 풀오버, 드레스, 코트, 샌들, 셔츠, 운동화, 가방, 발목 부츠 등 10가지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] 모듈 로딩 및 데이터 준비 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 모듈 로딩\n",
    "from sklearn.datasets import fetch_openml \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.optim as optim \n",
    "import torchmetrics.functional as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 데이터 로딩 \n",
    "db_name = 'Fashion-MNIST'\n",
    "\n",
    "# as_frame=False : ndarray 형식으로 반환\n",
    "fashion_data = fetch_openml(name=db_name, parser='auto', as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data   => int64, (70000, 784)\n",
      "target => object, (70000,)\n",
      "feature_names => ['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7', 'pixel8', 'pixel9', 'pixel10', 'pixel11', 'pixel12', 'pixel13', 'pixel14', 'pixel15', 'pixel16', 'pixel17', 'pixel18', 'pixel19', 'pixel20', 'pixel21', 'pixel22', 'pixel23', 'pixel24', 'pixel25', 'pixel26', 'pixel27', 'pixel28', 'pixel29', 'pixel30', 'pixel31', 'pixel32', 'pixel33', 'pixel34', 'pixel35', 'pixel36', 'pixel37', 'pixel38', 'pixel39', 'pixel40', 'pixel41', 'pixel42', 'pixel43', 'pixel44', 'pixel45', 'pixel46', 'pixel47', 'pixel48', 'pixel49', 'pixel50', 'pixel51', 'pixel52', 'pixel53', 'pixel54', 'pixel55', 'pixel56', 'pixel57', 'pixel58', 'pixel59', 'pixel60', 'pixel61', 'pixel62', 'pixel63', 'pixel64', 'pixel65', 'pixel66', 'pixel67', 'pixel68', 'pixel69', 'pixel70', 'pixel71', 'pixel72', 'pixel73', 'pixel74', 'pixel75', 'pixel76', 'pixel77', 'pixel78', 'pixel79', 'pixel80', 'pixel81', 'pixel82', 'pixel83', 'pixel84', 'pixel85', 'pixel86', 'pixel87', 'pixel88', 'pixel89', 'pixel90', 'pixel91', 'pixel92', 'pixel93', 'pixel94', 'pixel95', 'pixel96', 'pixel97', 'pixel98', 'pixel99', 'pixel100', 'pixel101', 'pixel102', 'pixel103', 'pixel104', 'pixel105', 'pixel106', 'pixel107', 'pixel108', 'pixel109', 'pixel110', 'pixel111', 'pixel112', 'pixel113', 'pixel114', 'pixel115', 'pixel116', 'pixel117', 'pixel118', 'pixel119', 'pixel120', 'pixel121', 'pixel122', 'pixel123', 'pixel124', 'pixel125', 'pixel126', 'pixel127', 'pixel128', 'pixel129', 'pixel130', 'pixel131', 'pixel132', 'pixel133', 'pixel134', 'pixel135', 'pixel136', 'pixel137', 'pixel138', 'pixel139', 'pixel140', 'pixel141', 'pixel142', 'pixel143', 'pixel144', 'pixel145', 'pixel146', 'pixel147', 'pixel148', 'pixel149', 'pixel150', 'pixel151', 'pixel152', 'pixel153', 'pixel154', 'pixel155', 'pixel156', 'pixel157', 'pixel158', 'pixel159', 'pixel160', 'pixel161', 'pixel162', 'pixel163', 'pixel164', 'pixel165', 'pixel166', 'pixel167', 'pixel168', 'pixel169', 'pixel170', 'pixel171', 'pixel172', 'pixel173', 'pixel174', 'pixel175', 'pixel176', 'pixel177', 'pixel178', 'pixel179', 'pixel180', 'pixel181', 'pixel182', 'pixel183', 'pixel184', 'pixel185', 'pixel186', 'pixel187', 'pixel188', 'pixel189', 'pixel190', 'pixel191', 'pixel192', 'pixel193', 'pixel194', 'pixel195', 'pixel196', 'pixel197', 'pixel198', 'pixel199', 'pixel200', 'pixel201', 'pixel202', 'pixel203', 'pixel204', 'pixel205', 'pixel206', 'pixel207', 'pixel208', 'pixel209', 'pixel210', 'pixel211', 'pixel212', 'pixel213', 'pixel214', 'pixel215', 'pixel216', 'pixel217', 'pixel218', 'pixel219', 'pixel220', 'pixel221', 'pixel222', 'pixel223', 'pixel224', 'pixel225', 'pixel226', 'pixel227', 'pixel228', 'pixel229', 'pixel230', 'pixel231', 'pixel232', 'pixel233', 'pixel234', 'pixel235', 'pixel236', 'pixel237', 'pixel238', 'pixel239', 'pixel240', 'pixel241', 'pixel242', 'pixel243', 'pixel244', 'pixel245', 'pixel246', 'pixel247', 'pixel248', 'pixel249', 'pixel250', 'pixel251', 'pixel252', 'pixel253', 'pixel254', 'pixel255', 'pixel256', 'pixel257', 'pixel258', 'pixel259', 'pixel260', 'pixel261', 'pixel262', 'pixel263', 'pixel264', 'pixel265', 'pixel266', 'pixel267', 'pixel268', 'pixel269', 'pixel270', 'pixel271', 'pixel272', 'pixel273', 'pixel274', 'pixel275', 'pixel276', 'pixel277', 'pixel278', 'pixel279', 'pixel280', 'pixel281', 'pixel282', 'pixel283', 'pixel284', 'pixel285', 'pixel286', 'pixel287', 'pixel288', 'pixel289', 'pixel290', 'pixel291', 'pixel292', 'pixel293', 'pixel294', 'pixel295', 'pixel296', 'pixel297', 'pixel298', 'pixel299', 'pixel300', 'pixel301', 'pixel302', 'pixel303', 'pixel304', 'pixel305', 'pixel306', 'pixel307', 'pixel308', 'pixel309', 'pixel310', 'pixel311', 'pixel312', 'pixel313', 'pixel314', 'pixel315', 'pixel316', 'pixel317', 'pixel318', 'pixel319', 'pixel320', 'pixel321', 'pixel322', 'pixel323', 'pixel324', 'pixel325', 'pixel326', 'pixel327', 'pixel328', 'pixel329', 'pixel330', 'pixel331', 'pixel332', 'pixel333', 'pixel334', 'pixel335', 'pixel336', 'pixel337', 'pixel338', 'pixel339', 'pixel340', 'pixel341', 'pixel342', 'pixel343', 'pixel344', 'pixel345', 'pixel346', 'pixel347', 'pixel348', 'pixel349', 'pixel350', 'pixel351', 'pixel352', 'pixel353', 'pixel354', 'pixel355', 'pixel356', 'pixel357', 'pixel358', 'pixel359', 'pixel360', 'pixel361', 'pixel362', 'pixel363', 'pixel364', 'pixel365', 'pixel366', 'pixel367', 'pixel368', 'pixel369', 'pixel370', 'pixel371', 'pixel372', 'pixel373', 'pixel374', 'pixel375', 'pixel376', 'pixel377', 'pixel378', 'pixel379', 'pixel380', 'pixel381', 'pixel382', 'pixel383', 'pixel384', 'pixel385', 'pixel386', 'pixel387', 'pixel388', 'pixel389', 'pixel390', 'pixel391', 'pixel392', 'pixel393', 'pixel394', 'pixel395', 'pixel396', 'pixel397', 'pixel398', 'pixel399', 'pixel400', 'pixel401', 'pixel402', 'pixel403', 'pixel404', 'pixel405', 'pixel406', 'pixel407', 'pixel408', 'pixel409', 'pixel410', 'pixel411', 'pixel412', 'pixel413', 'pixel414', 'pixel415', 'pixel416', 'pixel417', 'pixel418', 'pixel419', 'pixel420', 'pixel421', 'pixel422', 'pixel423', 'pixel424', 'pixel425', 'pixel426', 'pixel427', 'pixel428', 'pixel429', 'pixel430', 'pixel431', 'pixel432', 'pixel433', 'pixel434', 'pixel435', 'pixel436', 'pixel437', 'pixel438', 'pixel439', 'pixel440', 'pixel441', 'pixel442', 'pixel443', 'pixel444', 'pixel445', 'pixel446', 'pixel447', 'pixel448', 'pixel449', 'pixel450', 'pixel451', 'pixel452', 'pixel453', 'pixel454', 'pixel455', 'pixel456', 'pixel457', 'pixel458', 'pixel459', 'pixel460', 'pixel461', 'pixel462', 'pixel463', 'pixel464', 'pixel465', 'pixel466', 'pixel467', 'pixel468', 'pixel469', 'pixel470', 'pixel471', 'pixel472', 'pixel473', 'pixel474', 'pixel475', 'pixel476', 'pixel477', 'pixel478', 'pixel479', 'pixel480', 'pixel481', 'pixel482', 'pixel483', 'pixel484', 'pixel485', 'pixel486', 'pixel487', 'pixel488', 'pixel489', 'pixel490', 'pixel491', 'pixel492', 'pixel493', 'pixel494', 'pixel495', 'pixel496', 'pixel497', 'pixel498', 'pixel499', 'pixel500', 'pixel501', 'pixel502', 'pixel503', 'pixel504', 'pixel505', 'pixel506', 'pixel507', 'pixel508', 'pixel509', 'pixel510', 'pixel511', 'pixel512', 'pixel513', 'pixel514', 'pixel515', 'pixel516', 'pixel517', 'pixel518', 'pixel519', 'pixel520', 'pixel521', 'pixel522', 'pixel523', 'pixel524', 'pixel525', 'pixel526', 'pixel527', 'pixel528', 'pixel529', 'pixel530', 'pixel531', 'pixel532', 'pixel533', 'pixel534', 'pixel535', 'pixel536', 'pixel537', 'pixel538', 'pixel539', 'pixel540', 'pixel541', 'pixel542', 'pixel543', 'pixel544', 'pixel545', 'pixel546', 'pixel547', 'pixel548', 'pixel549', 'pixel550', 'pixel551', 'pixel552', 'pixel553', 'pixel554', 'pixel555', 'pixel556', 'pixel557', 'pixel558', 'pixel559', 'pixel560', 'pixel561', 'pixel562', 'pixel563', 'pixel564', 'pixel565', 'pixel566', 'pixel567', 'pixel568', 'pixel569', 'pixel570', 'pixel571', 'pixel572', 'pixel573', 'pixel574', 'pixel575', 'pixel576', 'pixel577', 'pixel578', 'pixel579', 'pixel580', 'pixel581', 'pixel582', 'pixel583', 'pixel584', 'pixel585', 'pixel586', 'pixel587', 'pixel588', 'pixel589', 'pixel590', 'pixel591', 'pixel592', 'pixel593', 'pixel594', 'pixel595', 'pixel596', 'pixel597', 'pixel598', 'pixel599', 'pixel600', 'pixel601', 'pixel602', 'pixel603', 'pixel604', 'pixel605', 'pixel606', 'pixel607', 'pixel608', 'pixel609', 'pixel610', 'pixel611', 'pixel612', 'pixel613', 'pixel614', 'pixel615', 'pixel616', 'pixel617', 'pixel618', 'pixel619', 'pixel620', 'pixel621', 'pixel622', 'pixel623', 'pixel624', 'pixel625', 'pixel626', 'pixel627', 'pixel628', 'pixel629', 'pixel630', 'pixel631', 'pixel632', 'pixel633', 'pixel634', 'pixel635', 'pixel636', 'pixel637', 'pixel638', 'pixel639', 'pixel640', 'pixel641', 'pixel642', 'pixel643', 'pixel644', 'pixel645', 'pixel646', 'pixel647', 'pixel648', 'pixel649', 'pixel650', 'pixel651', 'pixel652', 'pixel653', 'pixel654', 'pixel655', 'pixel656', 'pixel657', 'pixel658', 'pixel659', 'pixel660', 'pixel661', 'pixel662', 'pixel663', 'pixel664', 'pixel665', 'pixel666', 'pixel667', 'pixel668', 'pixel669', 'pixel670', 'pixel671', 'pixel672', 'pixel673', 'pixel674', 'pixel675', 'pixel676', 'pixel677', 'pixel678', 'pixel679', 'pixel680', 'pixel681', 'pixel682', 'pixel683', 'pixel684', 'pixel685', 'pixel686', 'pixel687', 'pixel688', 'pixel689', 'pixel690', 'pixel691', 'pixel692', 'pixel693', 'pixel694', 'pixel695', 'pixel696', 'pixel697', 'pixel698', 'pixel699', 'pixel700', 'pixel701', 'pixel702', 'pixel703', 'pixel704', 'pixel705', 'pixel706', 'pixel707', 'pixel708', 'pixel709', 'pixel710', 'pixel711', 'pixel712', 'pixel713', 'pixel714', 'pixel715', 'pixel716', 'pixel717', 'pixel718', 'pixel719', 'pixel720', 'pixel721', 'pixel722', 'pixel723', 'pixel724', 'pixel725', 'pixel726', 'pixel727', 'pixel728', 'pixel729', 'pixel730', 'pixel731', 'pixel732', 'pixel733', 'pixel734', 'pixel735', 'pixel736', 'pixel737', 'pixel738', 'pixel739', 'pixel740', 'pixel741', 'pixel742', 'pixel743', 'pixel744', 'pixel745', 'pixel746', 'pixel747', 'pixel748', 'pixel749', 'pixel750', 'pixel751', 'pixel752', 'pixel753', 'pixel754', 'pixel755', 'pixel756', 'pixel757', 'pixel758', 'pixel759', 'pixel760', 'pixel761', 'pixel762', 'pixel763', 'pixel764', 'pixel765', 'pixel766', 'pixel767', 'pixel768', 'pixel769', 'pixel770', 'pixel771', 'pixel772', 'pixel773', 'pixel774', 'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780', 'pixel781', 'pixel782', 'pixel783', 'pixel784']\n",
      "target_names => ['class']\n",
      "categories => {'class': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']}\n"
     ]
    }
   ],
   "source": [
    "### ===> 데이터 확인\n",
    "print(f'data   => {fashion_data[\"data\"].dtype}, {fashion_data[\"data\"].shape}')\n",
    "print(f'target => {fashion_data[\"target\"].dtype}, {fashion_data[\"target\"].shape}')\n",
    "print(f'feature_names => {fashion_data[\"feature_names\"]}\\ntarget_names => {fashion_data[\"target_names\"]}')\n",
    "print(f'categories => {fashion_data[\"categories\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] 데이터 전처리 - 피쳐와 타겟 분리, 정규화 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature => <class 'numpy.ndarray'>, (70000, 784)\n",
      "feature raw data =>\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   1   0   0  13  73   0   0   1   4   0   0   0\n",
      "    0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   3   0\n",
      "   36 136 127  62  54   0   0   0   1   3   4   0   0   3   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   6   0 102 204 176 134 144 123  23   0\n",
      "    0   0   0  12  10   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 155 236 207 178 107 156 161 109  64  23  77 130  72  15   0   0\n",
      "    0   0   0   0   0   0   0   0   0   1   0  69 207 223 218 216 216 163\n",
      "  127 121 122 146 141  88 172  66   0   0   0   0   0   0   0   0   0   1\n",
      "    1   1   0 200 232 232 233 229 223 223 215 213 164 127 123 196 229   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0 183 225 216 223 228\n",
      "  235 227 224 222 224 221 223 245 173   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0 193 228 218 213 198 180 212 210 211 213 223 220 243\n",
      "  202   0   0   0   0   0   0   0   0   0   0   1   3   0  12 219 220 212\n",
      "  218 192 169 227 208 218 224 212 226 197 209  52   0   0   0   0   0   0\n",
      "    0   0   0   0   6   0  99 244 222 220 218 203 198 221 215 213 222 220\n",
      "  245 119 167  56   0   0   0   0   0   0   0   0   0   4   0   0  55 236\n",
      "  228 230 228 240 232 213 218 223 234 217 217 209  92   0   0   0   1   4\n",
      "    6   7   2   0   0   0   0   0 237 226 217 223 222 219 222 221 216 223\n",
      "  229 215 218 255  77   0   0   3   0   0   0   0   0   0   0  62 145 204\n",
      "  228 207 213 221 218 208 211 218 224 223 219 215 224 244 159   0   0   0\n",
      "    0   0  18  44  82 107 189 228 220 222 217 226 200 205 211 230 224 234\n",
      "  176 188 250 248 233 238 215   0   0  57 187 208 224 221 224 208 204 214\n",
      "  208 209 200 159 245 193 206 223 255 255 221 234 221 211 220 232 246   0\n",
      "    3 202 228 224 221 211 211 214 205 205 205 220 240  80 150 255 229 221\n",
      "  188 154 191 210 204 209 222 228 225   0  98 233 198 210 222 229 229 234\n",
      "  249 220 194 215 217 241  65  73 106 117 168 219 221 215 217 223 223 224\n",
      "  229  29  75 204 212 204 193 205 211 225 216 185 197 206 198 213 240 195\n",
      "  227 245 239 223 218 212 209 222 220 221 230  67  48 203 183 194 213 197\n",
      "  185 190 194 192 202 214 219 221 220 236 225 216 199 206 186 181 177 172\n",
      "  181 205 206 115   0 122 219 193 179 171 183 196 204 210 213 207 211 210\n",
      "  200 196 194 191 195 191 198 192 176 156 167 177 210  92   0   0  74 189\n",
      "  212 191 175 172 175 181 185 188 189 188 193 198 204 209 210 210 211 188\n",
      "  188 194 192 216 170   0   2   0   0   0  66 200 222 237 239 242 246 243\n",
      "  244 221 220 193 191 179 182 182 181 176 166 168  99  58   0   0   0   0\n",
      "    0   0   0   0   0  40  61  44  72  41  35   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "\n",
      "target  => <class 'numpy.ndarray'>,(70000,)\n",
      "target raw data  => ['9']\n"
     ]
    }
   ],
   "source": [
    "### ===> 피쳐와 타겟 분리\n",
    "# sklearn dataset 에서 이미 처리 해둠\n",
    "feature=fashion_data['data']\n",
    "target=fashion_data['target']\n",
    "\n",
    "print(f'feature => {type(feature)}, {feature.shape}')\n",
    "print(f'feature raw data =>\\n{feature[:1]}\\n')\n",
    "\n",
    "print(f'target  => {type(target)},{target.shape}')\n",
    "print(f'target raw data  => {target[:1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_feature =>\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "norm_feature min => 0.0   max => 1.0\n"
     ]
    }
   ],
   "source": [
    "### ===> 정규화 : 피쳐\n",
    "# 이미지 데이터 값 0 ~ 255b\n",
    "norm_feature =feature/255.\n",
    "\n",
    "print(f'norm_feature =>\\n{norm_feature[:2]}')\n",
    "print(f'norm_feature min => {norm_feature.min()}   max => { norm_feature.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_target : int32 10개\n"
     ]
    }
   ],
   "source": [
    "### ===> 정규화 : 타겟\n",
    "# # 타겟 분류 클래스 : '0' ~ '9'  ==> 0 ~ 9 정수 변환\n",
    "norm_target=target.astype(int)\n",
    "print(f'norm_target : {norm_target.dtype} {np.unique(norm_target).size}개')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_target => (70000,), 1D\n",
      "[9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(f'norm_target => {norm_target.shape}, {norm_target.ndim}D\\n{norm_target[:5]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] 학습 데이터 셋 준비 - 훈련용, 검증용, 테스트용 데이터 셋 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [3-1] 사용자 정의 데이터 셋 및 전체 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 사용자정의 DataSet 클래스 \n",
    "# - 데이터의 Tensor 변환 \n",
    "class DLDataset(Dataset):\n",
    "    \n",
    "    # 초기화 함수 콜백함수(callback funcaion)\n",
    "    def __init__(self, x_data, y_data):\n",
    "        super().__init__()\n",
    "        # ndarray ==> tensor\n",
    "        self.feature=torch.FloatTensor(x_data)\n",
    "        self.target=torch.LongTensor(y_data)\n",
    "        \n",
    "        \n",
    "    # 데이터셋의 갯수 체크 함수 콜백함수(callback funcaion)\n",
    "    def __len__(self):\n",
    "        return self.target.shape[0]\n",
    "    \n",
    "    \n",
    "    # 특정 인덱스 데이터+라벨 반환 콜백함수(callback funcaion)\n",
    "    def __getitem__(self, index):\n",
    "        return self.feature[index], self.target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[all dataset] feature : torch.Size([70000, 784]),   target : torch.Size([70000])\n"
     ]
    }
   ],
   "source": [
    "### 전체 데이터셋 생성\n",
    "##  DataSet 생성\n",
    "all_dataset = DLDataset(norm_feature, norm_target)\n",
    "\n",
    "print(f'[all dataset] feature : {all_dataset.feature.shape},   target : {all_dataset.target.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [3-2] 학습용, 검증용, 테스트용 데이터셋 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset length    : 49000개\n",
      "Validation dataset      : 7000개\n",
      "Test dataset            : 14000개\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 고정 설정\n",
    "seed_gen=torch.Generator().manual_seed(42)\n",
    "\n",
    "TR_SIZE, VA_SIZE, TE_SIZE = 0.7, 0.1, 0.2\n",
    "\n",
    "trainDS, validDS, testDS = random_split(all_dataset, \n",
    "                                  [TR_SIZE, VA_SIZE, TE_SIZE], \n",
    "                                  generator=seed_gen)\n",
    "\n",
    "print(f\"Train dataset length    : {len(trainDS)}개\")\n",
    "print(f\"Validation dataset      : {len(validDS)}개\")\n",
    "print(f\"Test dataset            : {len(testDS)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] 데이터 로더 생성 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "TRAIN_DL = DataLoader(trainDS, batch_size=BATCH_SIZE)\n",
    "VALID_DL = DataLoader(validDS, batch_size=BATCH_SIZE)\n",
    "TEST_DL = DataLoader(testDS,   batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] 모델 준비 : 입력층 입력 수, 출력층 출력 수 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 다중 분류 모델\n",
    "### ===> 입력층 피쳐 수  : 28 * 28\n",
    "### ===> 출력층 피쳐 수  : 10 (0 ~ 9)\n",
    "class MNISTModel(nn.Module):\n",
    "    \n",
    "    # 모델 구성 요소 초기화 \n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Linear(in_dim, 200)\n",
    "        self.layer2=nn.Linear(200, 100)\n",
    "        self.layer3=nn.Linear(100, 50)\n",
    "        self.layer4=nn.Linear(50, out_dim)\n",
    "        self.relu=nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y=self.layer1(x)\n",
    "        y=self.relu(y)\n",
    "        y=self.layer2(y)\n",
    "        y=self.relu(y)\n",
    "        y=self.layer3(y)\n",
    "        y=self.relu(y)\n",
    "        y=self.layer4(y)\n",
    "        return y\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 학습 관련 함수 정의 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 학습 진행함수 \n",
    "def training(epoch, model, optimizer, dataLoader, device, loss_fn, classes):\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    model.train()\n",
    "    \n",
    "    # 배치크기 만큼 학습 진행 및 저장\n",
    "    train_report=[[], [], []]\n",
    "    for idx, (feature, target)  in enumerate(dataLoader):\n",
    "        # 배치크기만큼의 학습 데이터 준비\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "        \n",
    "        # 학습\n",
    "        pre_traget = model(feature)\n",
    "        \n",
    "        # 손실계산\n",
    "        loss = loss_fn(pre_traget, target)\n",
    "        train_report[0].append(loss)\n",
    "        \n",
    "        # 성능 평가\n",
    "        acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "        train_report[1].append(acc)\n",
    "        \n",
    "        f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "        train_report[2].append(f1)\n",
    "        \n",
    "        # W,b업데이트\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if not idx%50: print('.', end='') # 50번마다 점찍히게\n",
    "    \n",
    "    # 에포크 단위로 학습 모델 저장\n",
    "    ## 학습 중 모델 저장 관련 변수\n",
    "    dir = '../data/model/'   # 경로 변경할 때 이것만 수정하면 됨\n",
    "    filename = dir+'best_model.pth'\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(dir):  # 반환값 : True or False\n",
    "        os.mkdir(dir)\n",
    "    \n",
    "    \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(train_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(train_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(train_report[2])/BATCH_SIZE).item() \n",
    "    print(f'\\n[{epoch} Train ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ===> 검증 및 테스트 진행함수 \n",
    "def testing(epoch, model, dataLoader, device, loss_fn, classes, kind='valid'): # test는 optimizer 필요 X\n",
    "    # 학습모드 => 정규화, 경사하강법, 드랍아웃 등의 기능 활성화 \n",
    "    model.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        # 배치크기 만큼 학습 진행 및 저장\n",
    "        test_report=[[], [], []]\n",
    "        for idx, (feature, target)  in enumerate(dataLoader):\n",
    "            # 배치크기만큼의 학습 데이터 준비\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            # 학습\n",
    "            pre_traget = model(feature)\n",
    "\n",
    "            # 손실계산\n",
    "            loss = loss_fn(pre_traget, target)\n",
    "            test_report[0].append(loss)\n",
    "            \n",
    "            # 성능 평가 \n",
    "            acc = metrics.accuracy(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "            test_report[1].append(acc)\n",
    "            \n",
    "            f1 = metrics.f1_score(pre_traget, target, task='multiclass', num_classes=classes)\n",
    "            test_report[2].append(f1)\n",
    "            \n",
    "            #if not idx%50: print('.', end='')\n",
    "\n",
    "    testing_type = 'Valid' if kind == 'valid' else 'Test'\n",
    "        \n",
    "    # 에포크 단위 학습 진행 메시지 출력\n",
    "    loss_score = (sum(test_report[0])/BATCH_SIZE).item()\n",
    "    acc_score = (sum(test_report[1])/BATCH_SIZE).item()\n",
    "    f1_score = (sum(test_report[2])/BATCH_SIZE).item() \n",
    "    print(f'[{epoch} {testing_type} ] Loss ==> {loss_score:.3f} Acc ==> {acc_score:.3f} F1 ==> {f1_score:.3f}\\n')\n",
    "    \n",
    "    return loss_score, acc_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[7] 학습 : 학습 진행 준비, 학습 진행 <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [7-1] 학습 진행 준비 :  모델, 최적화, 학습횟수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행 디바이스 \n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 입출력 피쳐\n",
    "IN_DIM , OUT_DIM = norm_feature.shape[1], np.unique(norm_target).size\n",
    "\n",
    "# 모델 인스턴스 \n",
    "MODEL = MNISTModel(IN_DIM, OUT_DIM).to(DEVICE)\n",
    "\n",
    "# 최적화 인스턴스 생성\n",
    "OPTIMIZER = optim.SGD(MODEL.parameters())\n",
    "\n",
    "#  손실 함수\n",
    "LOSS_FN = nn.CrossEntropyLoss().to(DEVICE)\n",
    "\n",
    "# 학습 횟수 설정\n",
    "EPOCHS=100\n",
    "\n",
    "# 클래스 갯수\n",
    "ClASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [7-2] 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## 학습 중 모델 저장 관련 변수\n",
    "dir = '../data/model/'   # 경로 변경할 때 이것만 수정하면 됨\n",
    "filename = dir+'best_model.pth'\n",
    "\n",
    "import os\n",
    "if not os.path.exists(dir):  # 반환값 : True or False\n",
    "    os.mkdir(dir)       # 하위 폴더만 생성 즉, data 폴더는 이미 존재해야 함!\n",
    "#   os.makedirs(dir)    # 상위폴더도 생성해야할 때 사용\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T05:48:37.040335Z",
     "start_time": "2024-03-18T05:48:37.026465700Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/100] ....................\n",
      "[0 Train ] Loss ==> 45.016 Acc ==> 1.976 F1 ==> 1.976\n",
      "[0 Valid ] Loss ==> 6.405 Acc ==> 0.307 F1 ==> 0.307\n",
      "\n",
      "[Epoch 2/100] ....................\n",
      "[1 Train ] Loss ==> 44.641 Acc ==> 2.463 F1 ==> 2.463\n",
      "[1 Valid ] Loss ==> 6.341 Acc ==> 0.414 F1 ==> 0.414\n",
      "\n",
      "[Epoch 3/100] ....................\n",
      "[2 Train ] Loss ==> 44.022 Acc ==> 4.926 F1 ==> 4.926\n",
      "[2 Valid ] Loss ==> 6.220 Acc ==> 1.054 F1 ==> 1.054\n",
      "\n",
      "[Epoch 4/100] ....................\n",
      "[3 Train ] Loss ==> 42.746 Acc ==> 8.500 F1 ==> 8.500\n",
      "[3 Valid ] Loss ==> 5.959 Acc ==> 1.286 F1 ==> 1.286\n",
      "\n",
      "[Epoch 5/100] ....................\n",
      "[4 Train ] Loss ==> 40.128 Acc ==> 8.776 F1 ==> 8.776\n",
      "[4 Valid ] Loss ==> 5.461 Acc ==> 1.309 F1 ==> 1.309\n",
      "\n",
      "[Epoch 6/100] ....................\n",
      "[5 Train ] Loss ==> 35.595 Acc ==> 9.492 F1 ==> 9.492\n",
      "[5 Valid ] Loss ==> 4.669 Acc ==> 1.352 F1 ==> 1.352\n",
      "\n",
      "[Epoch 7/100] ....................\n",
      "[6 Train ] Loss ==> 29.739 Acc ==> 9.464 F1 ==> 9.464\n",
      "[6 Valid ] Loss ==> 3.886 Acc ==> 1.358 F1 ==> 1.358\n",
      "\n",
      "[Epoch 8/100] ....................\n",
      "[7 Train ] Loss ==> 25.300 Acc ==> 9.995 F1 ==> 9.995\n",
      "[7 Valid ] Loss ==> 3.397 Acc ==> 1.557 F1 ==> 1.557\n",
      "\n",
      "[Epoch 9/100] ....................\n",
      "[8 Train ] Loss ==> 22.461 Acc ==> 11.398 F1 ==> 11.398\n",
      "[8 Valid ] Loss ==> 3.066 Acc ==> 1.701 F1 ==> 1.701\n",
      "\n",
      "[Epoch 10/100] ....................\n",
      "[9 Train ] Loss ==> 20.416 Acc ==> 12.010 F1 ==> 12.010\n",
      "[9 Valid ] Loss ==> 2.813 Acc ==> 1.756 F1 ==> 1.756\n",
      "\n",
      "[Epoch 11/100] ....................\n",
      "[10 Train ] Loss ==> 18.822 Acc ==> 12.397 F1 ==> 12.397\n",
      "[10 Valid ] Loss ==> 2.611 Acc ==> 1.799 F1 ==> 1.799\n",
      "\n",
      "[Epoch 12/100] ....................\n",
      "[11 Train ] Loss ==> 17.581 Acc ==> 12.705 F1 ==> 12.705\n",
      "[11 Valid ] Loss ==> 2.454 Acc ==> 1.845 F1 ==> 1.845\n",
      "\n",
      "[Epoch 13/100] ....................\n",
      "[12 Train ] Loss ==> 16.648 Acc ==> 12.992 F1 ==> 12.992\n",
      "[12 Valid ] Loss ==> 2.337 Acc ==> 1.886 F1 ==> 1.886\n",
      "\n",
      "[Epoch 14/100] ....................\n",
      "[13 Train ] Loss ==> 15.961 Acc ==> 13.258 F1 ==> 13.258\n",
      "[13 Valid ] Loss ==> 2.250 Acc ==> 1.925 F1 ==> 1.925\n",
      "\n",
      "[Epoch 15/100] ....................\n",
      "[14 Train ] Loss ==> 15.436 Acc ==> 13.466 F1 ==> 13.466\n",
      "[14 Valid ] Loss ==> 2.182 Acc ==> 1.949 F1 ==> 1.949\n",
      "\n",
      "[Epoch 16/100] ....................\n",
      "[15 Train ] Loss ==> 15.016 Acc ==> 13.707 F1 ==> 13.707\n",
      "[15 Valid ] Loss ==> 2.126 Acc ==> 1.979 F1 ==> 1.979\n",
      "\n",
      "[Epoch 17/100] ....................\n",
      "[16 Train ] Loss ==> 14.658 Acc ==> 13.939 F1 ==> 13.939\n",
      "[16 Valid ] Loss ==> 2.077 Acc ==> 2.012 F1 ==> 2.012\n",
      "\n",
      "[Epoch 18/100] ....................\n",
      "[17 Train ] Loss ==> 14.339 Acc ==> 14.125 F1 ==> 14.125\n",
      "[17 Valid ] Loss ==> 2.033 Acc ==> 2.038 F1 ==> 2.038\n",
      "\n",
      "[Epoch 19/100] ....................\n",
      "[18 Train ] Loss ==> 14.048 Acc ==> 14.298 F1 ==> 14.298\n",
      "[18 Valid ] Loss ==> 1.992 Acc ==> 2.058 F1 ==> 2.058\n",
      "\n",
      "[Epoch 20/100] ....................\n",
      "[19 Train ] Loss ==> 13.776 Acc ==> 14.444 F1 ==> 14.444\n",
      "[19 Valid ] Loss ==> 1.955 Acc ==> 2.072 F1 ==> 2.072\n",
      "\n",
      "[Epoch 21/100] ....................\n",
      "[20 Train ] Loss ==> 13.524 Acc ==> 14.579 F1 ==> 14.579\n",
      "[20 Valid ] Loss ==> 1.919 Acc ==> 2.091 F1 ==> 2.091\n",
      "\n",
      "[Epoch 22/100] ....................\n",
      "[21 Train ] Loss ==> 13.289 Acc ==> 14.700 F1 ==> 14.700\n",
      "[21 Valid ] Loss ==> 1.886 Acc ==> 2.108 F1 ==> 2.108\n",
      "\n",
      "[Epoch 23/100] ....................\n",
      "[22 Train ] Loss ==> 13.071 Acc ==> 14.802 F1 ==> 14.802\n",
      "[22 Valid ] Loss ==> 1.856 Acc ==> 2.124 F1 ==> 2.124\n",
      "\n",
      "[Epoch 24/100] ....................\n",
      "[23 Train ] Loss ==> 12.870 Acc ==> 14.901 F1 ==> 14.901\n",
      "[23 Valid ] Loss ==> 1.828 Acc ==> 2.140 F1 ==> 2.140\n",
      "\n",
      "[Epoch 25/100] ....................\n",
      "[24 Train ] Loss ==> 12.683 Acc ==> 14.991 F1 ==> 14.991\n",
      "[24 Valid ] Loss ==> 1.802 Acc ==> 2.153 F1 ==> 2.153\n",
      "\n",
      "[Epoch 26/100] ....................\n",
      "[25 Train ] Loss ==> 12.510 Acc ==> 15.065 F1 ==> 15.065\n",
      "[25 Valid ] Loss ==> 1.777 Acc ==> 2.165 F1 ==> 2.165\n",
      "\n",
      "[Epoch 27/100] ....................\n",
      "[26 Train ] Loss ==> 12.349 Acc ==> 15.127 F1 ==> 15.127\n",
      "[26 Valid ] Loss ==> 1.755 Acc ==> 2.173 F1 ==> 2.173\n",
      "\n",
      "[Epoch 28/100] ....................\n",
      "[27 Train ] Loss ==> 12.200 Acc ==> 15.198 F1 ==> 15.198\n",
      "[27 Valid ] Loss ==> 1.734 Acc ==> 2.184 F1 ==> 2.184\n",
      "\n",
      "[Epoch 29/100] ....................\n",
      "[28 Train ] Loss ==> 12.062 Acc ==> 15.263 F1 ==> 15.263\n",
      "[28 Valid ] Loss ==> 1.714 Acc ==> 2.196 F1 ==> 2.196\n",
      "\n",
      "[Epoch 30/100] ....................\n",
      "[29 Train ] Loss ==> 11.933 Acc ==> 15.326 F1 ==> 15.326\n",
      "[29 Valid ] Loss ==> 1.696 Acc ==> 2.206 F1 ==> 2.206\n",
      "\n",
      "[Epoch 31/100] ....................\n",
      "[30 Train ] Loss ==> 11.812 Acc ==> 15.378 F1 ==> 15.378\n",
      "[30 Valid ] Loss ==> 1.679 Acc ==> 2.209 F1 ==> 2.209\n",
      "\n",
      "[Epoch 32/100] ....................\n",
      "[31 Train ] Loss ==> 11.698 Acc ==> 15.442 F1 ==> 15.442\n",
      "[31 Valid ] Loss ==> 1.663 Acc ==> 2.214 F1 ==> 2.214\n",
      "\n",
      "[Epoch 33/100] ....................\n",
      "[32 Train ] Loss ==> 11.589 Acc ==> 15.492 F1 ==> 15.492\n",
      "[32 Valid ] Loss ==> 1.648 Acc ==> 2.223 F1 ==> 2.223\n",
      "\n",
      "[Epoch 34/100] ....................\n",
      "[33 Train ] Loss ==> 11.486 Acc ==> 15.536 F1 ==> 15.536\n",
      "[33 Valid ] Loss ==> 1.633 Acc ==> 2.230 F1 ==> 2.230\n",
      "\n",
      "[Epoch 35/100] ....................\n",
      "[34 Train ] Loss ==> 11.388 Acc ==> 15.580 F1 ==> 15.580\n",
      "[34 Valid ] Loss ==> 1.619 Acc ==> 2.235 F1 ==> 2.235\n",
      "\n",
      "[Epoch 36/100] ....................\n",
      "[35 Train ] Loss ==> 11.296 Acc ==> 15.616 F1 ==> 15.616\n",
      "[35 Valid ] Loss ==> 1.607 Acc ==> 2.240 F1 ==> 2.240\n",
      "\n",
      "[Epoch 37/100] ....................\n",
      "[36 Train ] Loss ==> 11.207 Acc ==> 15.659 F1 ==> 15.659\n",
      "[36 Valid ] Loss ==> 1.594 Acc ==> 2.248 F1 ==> 2.248\n",
      "\n",
      "[Epoch 38/100] ....................\n",
      "[37 Train ] Loss ==> 11.123 Acc ==> 15.698 F1 ==> 15.698\n",
      "[37 Valid ] Loss ==> 1.582 Acc ==> 2.256 F1 ==> 2.256\n",
      "\n",
      "[Epoch 39/100] ....................\n",
      "[38 Train ] Loss ==> 11.042 Acc ==> 15.738 F1 ==> 15.738\n",
      "[38 Valid ] Loss ==> 1.571 Acc ==> 2.262 F1 ==> 2.262\n",
      "\n",
      "[Epoch 40/100] ....................\n",
      "[39 Train ] Loss ==> 10.963 Acc ==> 15.773 F1 ==> 15.773\n",
      "[39 Valid ] Loss ==> 1.560 Acc ==> 2.263 F1 ==> 2.263\n",
      "\n",
      "[Epoch 41/100] ....................\n",
      "[40 Train ] Loss ==> 10.888 Acc ==> 15.808 F1 ==> 15.808\n",
      "[40 Valid ] Loss ==> 1.550 Acc ==> 2.264 F1 ==> 2.264\n",
      "\n",
      "[Epoch 42/100] ....................\n",
      "[41 Train ] Loss ==> 10.815 Acc ==> 15.826 F1 ==> 15.826\n",
      "[41 Valid ] Loss ==> 1.540 Acc ==> 2.266 F1 ==> 2.266\n",
      "\n",
      "[Epoch 43/100] ....................\n",
      "[42 Train ] Loss ==> 10.745 Acc ==> 15.852 F1 ==> 15.852\n",
      "[42 Valid ] Loss ==> 1.530 Acc ==> 2.270 F1 ==> 2.270\n",
      "\n",
      "[Epoch 44/100] ....................\n",
      "[43 Train ] Loss ==> 10.677 Acc ==> 15.880 F1 ==> 15.880\n",
      "[43 Valid ] Loss ==> 1.520 Acc ==> 2.273 F1 ==> 2.273\n",
      "\n",
      "[Epoch 45/100] ....................\n",
      "[44 Train ] Loss ==> 10.610 Acc ==> 15.897 F1 ==> 15.897\n",
      "[44 Valid ] Loss ==> 1.511 Acc ==> 2.276 F1 ==> 2.276\n",
      "\n",
      "[Epoch 46/100] ....................\n",
      "[45 Train ] Loss ==> 10.546 Acc ==> 15.921 F1 ==> 15.921\n",
      "[45 Valid ] Loss ==> 1.502 Acc ==> 2.278 F1 ==> 2.278\n",
      "\n",
      "[Epoch 47/100] ....................\n",
      "[46 Train ] Loss ==> 10.482 Acc ==> 15.942 F1 ==> 15.942\n",
      "[46 Valid ] Loss ==> 1.493 Acc ==> 2.283 F1 ==> 2.283\n",
      "\n",
      "[Epoch 48/100] ....................\n",
      "[47 Train ] Loss ==> 10.421 Acc ==> 15.959 F1 ==> 15.959\n",
      "[47 Valid ] Loss ==> 1.485 Acc ==> 2.288 F1 ==> 2.288\n",
      "\n",
      "[Epoch 49/100] ....................\n",
      "[48 Train ] Loss ==> 10.360 Acc ==> 15.984 F1 ==> 15.984\n",
      "[48 Valid ] Loss ==> 1.476 Acc ==> 2.291 F1 ==> 2.291\n",
      "\n",
      "[Epoch 50/100] ....................\n",
      "[49 Train ] Loss ==> 10.301 Acc ==> 16.000 F1 ==> 16.000\n",
      "[49 Valid ] Loss ==> 1.468 Acc ==> 2.293 F1 ==> 2.293\n",
      "\n",
      "[Epoch 51/100] ....................\n",
      "[50 Train ] Loss ==> 10.242 Acc ==> 16.018 F1 ==> 16.018\n",
      "[50 Valid ] Loss ==> 1.460 Acc ==> 2.298 F1 ==> 2.298\n",
      "\n",
      "[Epoch 52/100] ....................\n",
      "[51 Train ] Loss ==> 10.183 Acc ==> 16.038 F1 ==> 16.038\n",
      "[51 Valid ] Loss ==> 1.452 Acc ==> 2.303 F1 ==> 2.303\n",
      "\n",
      "[Epoch 53/100] ....................\n",
      "[52 Train ] Loss ==> 10.126 Acc ==> 16.057 F1 ==> 16.057\n",
      "[52 Valid ] Loss ==> 1.444 Acc ==> 2.308 F1 ==> 2.308\n",
      "\n",
      "[Epoch 54/100] ....................\n",
      "[53 Train ] Loss ==> 10.069 Acc ==> 16.078 F1 ==> 16.078\n",
      "[53 Valid ] Loss ==> 1.436 Acc ==> 2.310 F1 ==> 2.310\n",
      "\n",
      "[Epoch 55/100] ....................\n",
      "[54 Train ] Loss ==> 10.014 Acc ==> 16.100 F1 ==> 16.100\n",
      "[54 Valid ] Loss ==> 1.428 Acc ==> 2.312 F1 ==> 2.312\n",
      "\n",
      "[Epoch 56/100] ....................\n",
      "[55 Train ] Loss ==> 9.959 Acc ==> 16.123 F1 ==> 16.123\n",
      "[55 Valid ] Loss ==> 1.421 Acc ==> 2.314 F1 ==> 2.314\n",
      "\n",
      "[Epoch 57/100] ....................\n",
      "[56 Train ] Loss ==> 9.905 Acc ==> 16.141 F1 ==> 16.141\n",
      "[56 Valid ] Loss ==> 1.413 Acc ==> 2.318 F1 ==> 2.318\n",
      "\n",
      "[Epoch 58/100] ....................\n",
      "[57 Train ] Loss ==> 9.852 Acc ==> 16.165 F1 ==> 16.165\n",
      "[57 Valid ] Loss ==> 1.405 Acc ==> 2.318 F1 ==> 2.318\n",
      "\n",
      "[Epoch 59/100] ....................\n",
      "[58 Train ] Loss ==> 9.799 Acc ==> 16.189 F1 ==> 16.189\n",
      "[58 Valid ] Loss ==> 1.398 Acc ==> 2.322 F1 ==> 2.322\n",
      "\n",
      "[Epoch 60/100] ....................\n",
      "[59 Train ] Loss ==> 9.747 Acc ==> 16.207 F1 ==> 16.207\n",
      "[59 Valid ] Loss ==> 1.391 Acc ==> 2.324 F1 ==> 2.324\n",
      "\n",
      "[Epoch 61/100] ....................\n",
      "[60 Train ] Loss ==> 9.696 Acc ==> 16.227 F1 ==> 16.227\n",
      "[60 Valid ] Loss ==> 1.383 Acc ==> 2.326 F1 ==> 2.326\n",
      "\n",
      "[Epoch 62/100] ....................\n",
      "[61 Train ] Loss ==> 9.646 Acc ==> 16.238 F1 ==> 16.238\n",
      "[61 Valid ] Loss ==> 1.376 Acc ==> 2.331 F1 ==> 2.331\n",
      "\n",
      "[Epoch 63/100] ....................\n",
      "[62 Train ] Loss ==> 9.597 Acc ==> 16.255 F1 ==> 16.255\n",
      "[62 Valid ] Loss ==> 1.369 Acc ==> 2.335 F1 ==> 2.335\n",
      "\n",
      "[Epoch 64/100] ....................\n",
      "[63 Train ] Loss ==> 9.548 Acc ==> 16.268 F1 ==> 16.268\n",
      "[63 Valid ] Loss ==> 1.362 Acc ==> 2.338 F1 ==> 2.338\n",
      "\n",
      "[Epoch 65/100] ....................\n",
      "[64 Train ] Loss ==> 9.500 Acc ==> 16.288 F1 ==> 16.288\n",
      "[64 Valid ] Loss ==> 1.355 Acc ==> 2.338 F1 ==> 2.338\n",
      "\n",
      "[Epoch 66/100] ....................\n",
      "[65 Train ] Loss ==> 9.453 Acc ==> 16.301 F1 ==> 16.301\n",
      "[65 Valid ] Loss ==> 1.349 Acc ==> 2.342 F1 ==> 2.342\n",
      "\n",
      "[Epoch 67/100] ....................\n",
      "[66 Train ] Loss ==> 9.407 Acc ==> 16.317 F1 ==> 16.317\n",
      "[66 Valid ] Loss ==> 1.342 Acc ==> 2.343 F1 ==> 2.343\n",
      "\n",
      "[Epoch 68/100] ....................\n",
      "[67 Train ] Loss ==> 9.362 Acc ==> 16.332 F1 ==> 16.332\n",
      "[67 Valid ] Loss ==> 1.336 Acc ==> 2.344 F1 ==> 2.344\n",
      "\n",
      "[Epoch 69/100] ....................\n",
      "[68 Train ] Loss ==> 9.317 Acc ==> 16.342 F1 ==> 16.342\n",
      "[68 Valid ] Loss ==> 1.329 Acc ==> 2.346 F1 ==> 2.346\n",
      "\n",
      "[Epoch 70/100] ....................\n",
      "[69 Train ] Loss ==> 9.274 Acc ==> 16.351 F1 ==> 16.351\n",
      "[69 Valid ] Loss ==> 1.323 Acc ==> 2.347 F1 ==> 2.347\n",
      "\n",
      "[Epoch 71/100] ....................\n",
      "[70 Train ] Loss ==> 9.231 Acc ==> 16.368 F1 ==> 16.368\n",
      "[70 Valid ] Loss ==> 1.317 Acc ==> 2.352 F1 ==> 2.352\n",
      "\n",
      "[Epoch 72/100] ....................\n",
      "[71 Train ] Loss ==> 9.189 Acc ==> 16.383 F1 ==> 16.383\n",
      "[71 Valid ] Loss ==> 1.311 Acc ==> 2.354 F1 ==> 2.354\n",
      "\n",
      "[Epoch 73/100] ....................\n",
      "[72 Train ] Loss ==> 9.147 Acc ==> 16.397 F1 ==> 16.397\n",
      "[72 Valid ] Loss ==> 1.306 Acc ==> 2.356 F1 ==> 2.356\n",
      "\n",
      "[Epoch 74/100] ....................\n",
      "[73 Train ] Loss ==> 9.107 Acc ==> 16.412 F1 ==> 16.412\n",
      "[73 Valid ] Loss ==> 1.300 Acc ==> 2.355 F1 ==> 2.355\n",
      "\n",
      "[Epoch 75/100] ....................\n",
      "[74 Train ] Loss ==> 9.067 Acc ==> 16.425 F1 ==> 16.425\n",
      "[74 Valid ] Loss ==> 1.295 Acc ==> 2.356 F1 ==> 2.356\n",
      "\n",
      "[Epoch 76/100] ....................\n",
      "[75 Train ] Loss ==> 9.028 Acc ==> 16.445 F1 ==> 16.445\n",
      "[75 Valid ] Loss ==> 1.289 Acc ==> 2.358 F1 ==> 2.358\n",
      "\n",
      "[Epoch 77/100] ....................\n",
      "[76 Train ] Loss ==> 8.989 Acc ==> 16.466 F1 ==> 16.466\n",
      "[76 Valid ] Loss ==> 1.284 Acc ==> 2.361 F1 ==> 2.361\n",
      "\n",
      "[Epoch 78/100] ....................\n",
      "[77 Train ] Loss ==> 8.952 Acc ==> 16.478 F1 ==> 16.478\n",
      "[77 Valid ] Loss ==> 1.279 Acc ==> 2.363 F1 ==> 2.363\n",
      "\n",
      "[Epoch 79/100] ....................\n",
      "[78 Train ] Loss ==> 8.915 Acc ==> 16.489 F1 ==> 16.489\n",
      "[78 Valid ] Loss ==> 1.274 Acc ==> 2.364 F1 ==> 2.364\n",
      "\n",
      "[Epoch 80/100] ....................\n",
      "[79 Train ] Loss ==> 8.878 Acc ==> 16.507 F1 ==> 16.507\n",
      "[79 Valid ] Loss ==> 1.269 Acc ==> 2.365 F1 ==> 2.365\n",
      "\n",
      "[Epoch 81/100] ....................\n",
      "[80 Train ] Loss ==> 8.842 Acc ==> 16.517 F1 ==> 16.517\n",
      "[80 Valid ] Loss ==> 1.264 Acc ==> 2.366 F1 ==> 2.366\n",
      "\n",
      "[Epoch 82/100] ....................\n",
      "[81 Train ] Loss ==> 8.807 Acc ==> 16.527 F1 ==> 16.527\n",
      "[81 Valid ] Loss ==> 1.259 Acc ==> 2.368 F1 ==> 2.368\n",
      "\n",
      "[Epoch 83/100] ....................\n",
      "[82 Train ] Loss ==> 8.772 Acc ==> 16.541 F1 ==> 16.541\n",
      "[82 Valid ] Loss ==> 1.255 Acc ==> 2.369 F1 ==> 2.369\n",
      "\n",
      "[Epoch 84/100] ....................\n",
      "[83 Train ] Loss ==> 8.738 Acc ==> 16.549 F1 ==> 16.549\n",
      "[83 Valid ] Loss ==> 1.250 Acc ==> 2.370 F1 ==> 2.370\n",
      "\n",
      "[Epoch 85/100] ....................\n",
      "[84 Train ] Loss ==> 8.705 Acc ==> 16.568 F1 ==> 16.568\n",
      "[84 Valid ] Loss ==> 1.246 Acc ==> 2.372 F1 ==> 2.372\n",
      "\n",
      "[Epoch 86/100] ....................\n",
      "[85 Train ] Loss ==> 8.672 Acc ==> 16.582 F1 ==> 16.582\n",
      "[85 Valid ] Loss ==> 1.242 Acc ==> 2.373 F1 ==> 2.373\n",
      "\n",
      "[Epoch 87/100] ....................\n",
      "[86 Train ] Loss ==> 8.639 Acc ==> 16.592 F1 ==> 16.592\n",
      "[86 Valid ] Loss ==> 1.238 Acc ==> 2.374 F1 ==> 2.374\n",
      "\n",
      "[Epoch 88/100] ....................\n",
      "[87 Train ] Loss ==> 8.608 Acc ==> 16.599 F1 ==> 16.599\n",
      "[87 Valid ] Loss ==> 1.234 Acc ==> 2.378 F1 ==> 2.378\n",
      "\n",
      "[Epoch 89/100] ....................\n",
      "[88 Train ] Loss ==> 8.576 Acc ==> 16.614 F1 ==> 16.614\n",
      "[88 Valid ] Loss ==> 1.230 Acc ==> 2.379 F1 ==> 2.379\n",
      "\n",
      "[Epoch 90/100] ....................\n",
      "[89 Train ] Loss ==> 8.545 Acc ==> 16.623 F1 ==> 16.623\n",
      "[89 Valid ] Loss ==> 1.226 Acc ==> 2.382 F1 ==> 2.382\n",
      "\n",
      "[Epoch 91/100] ....................\n",
      "[90 Train ] Loss ==> 8.514 Acc ==> 16.634 F1 ==> 16.634\n",
      "[90 Valid ] Loss ==> 1.222 Acc ==> 2.383 F1 ==> 2.383\n",
      "\n",
      "[Epoch 92/100] ....................\n",
      "[91 Train ] Loss ==> 8.484 Acc ==> 16.647 F1 ==> 16.647\n",
      "[91 Valid ] Loss ==> 1.218 Acc ==> 2.385 F1 ==> 2.385\n",
      "\n",
      "[Epoch 93/100] ....................\n",
      "[92 Train ] Loss ==> 8.454 Acc ==> 16.656 F1 ==> 16.656\n",
      "[92 Valid ] Loss ==> 1.214 Acc ==> 2.387 F1 ==> 2.387\n",
      "\n",
      "[Epoch 94/100] ....................\n",
      "[93 Train ] Loss ==> 8.425 Acc ==> 16.666 F1 ==> 16.666\n",
      "[93 Valid ] Loss ==> 1.211 Acc ==> 2.389 F1 ==> 2.389\n",
      "\n",
      "[Epoch 95/100] ....................\n",
      "[94 Train ] Loss ==> 8.395 Acc ==> 16.679 F1 ==> 16.679\n",
      "[94 Valid ] Loss ==> 1.207 Acc ==> 2.390 F1 ==> 2.390\n",
      "\n",
      "[Epoch 96/100] ....................\n",
      "[95 Train ] Loss ==> 8.367 Acc ==> 16.700 F1 ==> 16.700\n",
      "[95 Valid ] Loss ==> 1.204 Acc ==> 2.392 F1 ==> 2.392\n",
      "\n",
      "[Epoch 97/100] ....................\n",
      "[96 Train ] Loss ==> 8.339 Acc ==> 16.711 F1 ==> 16.711\n",
      "[96 Valid ] Loss ==> 1.200 Acc ==> 2.393 F1 ==> 2.393\n",
      "\n",
      "[Epoch 98/100] ....................\n",
      "[97 Train ] Loss ==> 8.311 Acc ==> 16.725 F1 ==> 16.725\n",
      "[97 Valid ] Loss ==> 1.197 Acc ==> 2.394 F1 ==> 2.394\n",
      "\n",
      "[Epoch 99/100] ....................\n",
      "[98 Train ] Loss ==> 8.283 Acc ==> 16.734 F1 ==> 16.734\n",
      "[98 Valid ] Loss ==> 1.194 Acc ==> 2.395 F1 ==> 2.395\n",
      "\n",
      "[Epoch 100/100] ....................\n",
      "[99 Train ] Loss ==> 8.256 Acc ==> 16.743 F1 ==> 16.743\n",
      "[99 Valid ] Loss ==> 1.190 Acc ==> 2.397 F1 ==> 2.397\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_ = {'loss':[], 'acc':[], 'f1':[]}\n",
    "val_ = {'loss':[], 'acc':[], 'f1':[]}\n",
    "for epo in range(EPOCHS):\n",
    "    print(f\"[Epoch {epo+1}/{EPOCHS}] \", end='')\n",
    "    tr_score=training(epo, MODEL,OPTIMIZER, TRAIN_DL, DEVICE, LOSS_FN, OUT_DIM)\n",
    "    va_score=testing(epo, MODEL, VALID_DL, DEVICE, LOSS_FN, OUT_DIM)\n",
    "    \n",
    "    for idx, key in enumerate(train_): # enumerate는 인덱스 반환( dict에서 인덱스는 key값 )\n",
    "        train_[key].append(tr_score[idx])\n",
    "        val_[key].append(va_score[idx])\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [7-3] 학습 후 평가 : Loss, Acc, F1 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  [12.341072082519531, 12.123558044433594, 11.923877716064453]\n",
      "acc  [15.220023155212402, 15.29681396484375, 15.368409156799316]\n",
      "f1  [15.220023155212402, 15.29681396484375, 15.368409156799316]\n"
     ]
    }
   ],
   "source": [
    "for idx, key in enumerate(train_):\n",
    "    print(f'{key} ', train_[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[6] 테스트 <hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "뒤지겟네"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_PY38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
